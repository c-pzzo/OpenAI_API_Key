{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352f1d23",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485630d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a9c69",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c814493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4e311",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98af5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the API key from a local file\n",
    "# <Edit Here the path to your OpenAI API Key location>\n",
    "key_file = pd.read_csv(r'.../path_to_API_Key_location/openai_api.txt', header=None)\n",
    "# Store the key in a variable\n",
    "openai.api_key = key_file[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd0676c",
   "metadata": {},
   "source": [
    "# > Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45888e0b",
   "metadata": {},
   "source": [
    "## >> Connection test: Calling available models using OPENAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188de5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available models \n",
    "if False:\n",
    "    model_lst = openai.Model.list()\n",
    "    model_lst\n",
    "    \n",
    "    # List of engine names \n",
    "    for i in model_lst['data']:\n",
    "        print(i['id'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58471744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results in JSON file; so not to use the API key everytime.\n",
    "if False:\n",
    "    with open('openai_models.json', 'w') as models:\n",
    "        models.write(str(model_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4d41150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Available engines:\n",
      "babbage\n",
      "davinci\n",
      "text-davinci-edit-001\n",
      "babbage-code-search-code\n",
      "text-similarity-babbage-001\n",
      "code-davinci-edit-001\n",
      "text-davinci-001\n",
      "ada\n",
      "babbage-code-search-text\n",
      "babbage-similarity\n",
      "code-search-babbage-text-001\n",
      "text-curie-001\n",
      "whisper-1\n",
      "code-search-babbage-code-001\n",
      "text-davinci-003\n",
      "text-ada-001\n",
      "text-embedding-ada-002\n",
      "text-similarity-ada-001\n",
      "curie-instruct-beta\n",
      "ada-code-search-code\n",
      "ada-similarity\n",
      "code-search-ada-text-001\n",
      "text-search-ada-query-001\n",
      "davinci-search-document\n",
      "ada-code-search-text\n",
      "text-search-ada-doc-001\n",
      "davinci-instruct-beta\n",
      "text-similarity-curie-001\n",
      "code-search-ada-code-001\n",
      "ada-search-query\n",
      "text-search-davinci-query-001\n",
      "curie-search-query\n",
      "davinci-search-query\n",
      "babbage-search-document\n",
      "ada-search-document\n",
      "text-search-curie-query-001\n",
      "text-search-babbage-doc-001\n",
      "curie-search-document\n",
      "text-search-curie-doc-001\n",
      "babbage-search-query\n",
      "text-babbage-001\n",
      "text-search-davinci-doc-001\n",
      "text-search-babbage-query-001\n",
      "curie-similarity\n",
      "gpt-3.5-turbo-0301\n",
      "curie\n",
      "gpt-3.5-turbo\n",
      "text-similarity-davinci-001\n",
      "text-davinci-002\n",
      "davinci-similarity\n",
      "cushman:2020-05-03\n",
      "ada:2020-05-03\n",
      "babbage:2020-05-03\n",
      "curie:2020-05-03\n",
      "davinci:2020-05-03\n",
      "if-davinci-v2\n",
      "if-curie-v2\n",
      "if-davinci:3.0.0\n",
      "davinci-if:3.0.0\n",
      "davinci-instruct-beta:2.0.0\n",
      "text-ada:001\n",
      "text-davinci:001\n",
      "text-curie:001\n",
      "text-babbage:001\n"
     ]
    }
   ],
   "source": [
    "# Opening local JSON file with OPENAI models\n",
    "model_lst = json.load(open('openai_models.json'))\n",
    "\n",
    "print(\"> Available engines:\")\n",
    "for i in model_lst['data']:\n",
    "    print(i['id'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a68ac4",
   "metadata": {},
   "source": [
    "## >> Prompting ChatGPT for a single reply.\n",
    "The following code uses the model `gpt-3.5-turbo`. It needs the /v1/chat/completions **endpoint**. If the engine were to be changed for an engine with another type of endpoint, then probably the code won't run. It was tested with \"davinci\" and it didn't run because this engine requires a /chat/completions endpoint. They require different code. Check [here](https://platform.openai.com/docs/models/model-endpoint-compatibility) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6dff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT: ChatGPT is an AI-powered chatbot platform that provides conversational experiences and assistance on a variety of topics.\n"
     ]
    }
   ],
   "source": [
    "text_prompt = \"Describe ChatGPT in one sentence\"\n",
    "messages = [ {\"role\": \"system\", \"content\": \"API connection test.\"} ]\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": text_prompt})\n",
    "chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\"\n",
    "                                    , messages=messages\n",
    "                                    , max_tokens=60\n",
    "                                    , n=1\n",
    "                                    , stop=None\n",
    "                                    , temperature=0.5)\n",
    "\n",
    "reply = chat.choices[0].message.content\n",
    "print(f\"ChatGPT: {reply}\")\n",
    "messages.append({\"role\": \"assistant\", \"content\": reply})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a38404",
   "metadata": {},
   "source": [
    "* prompt: Input text for ChatGPT.\n",
    "* model: The engine that the API will connect to.\n",
    "* max_token: Maximum number of tokens (i.e. words or phrases) for the generated text.\n",
    "* temperature: value ∈ [0, 1]. Controls the randomness of the generated text. Higher value is more random, and vice versa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be3bcf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChatGPT is an AI-powered chatbot platform that provides conversational experiences and assistance on a variety of topics.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing local variable with OPENAI response\n",
    "reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b9feaa",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "* [OpenAI API: Complete Python Tutorial](https://analyzingalpha.com/openai-api-python-tutorial)\n",
    "* [Listing Available OpenAI Models – OpenAI API](https://holypython.com/python-api-tutorial/listing-all-available-openai-models-openai-api/)\n",
    "* [Read JSON file using Python](https://www.geeksforgeeks.org/read-json-file-using-python/)\n",
    "* [Models](https://platform.openai.com/docs/models/gpt-3-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
